{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from typing import Any, Dict, Iterator, List\n",
    "\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "from auto_ml.model import AutoMLModel\n",
    "from custom_data_types import AutoMLData\n",
    "from data_collection.column_selection import get_dataset\n",
    "from data_preprocessing.preprocessing import autoML_prep, feature_generation\n",
    "from dataprofiling.data_summary import DataSummary\n",
    "from model_assessment.fairness import FairnessAssessor\n",
    "\n",
    "datasets = [\n",
    "    \"https://www.kaggle.com/datasets/prasad22/healthcare-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/willianoliveiragibin/healthcare-insurance\",\n",
    "    \"https://www.kaggle.com/datasets/nanditapore/healthcare-diabetes\",\n",
    "    \"https://www.kaggle.com/datasets/jpmiller/employee-attrition-for-healthcare\",\n",
    "    \"https://www.kaggle.com/datasets/wajahat1064/healthcare-appointment-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/deependraverma13/diabetes-healthcare-comprehensive-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/babyoda/healthcare-investments-and-length-of-hospital-stay\",\n",
    "    \"https://www.kaggle.com/datasets/anmolkumar/janatahack-healthcare-analytics-part-2\",\n",
    "    \"https://www.kaggle.com/datasets/kalilurrahman/united-healthcare-stock-data\",\n",
    "    \"https://www.kaggle.com/datasets/amandam1/breastcancerdataset\",\n",
    "    \"https://huggingface.co/datasets/mstz/madelon\",\n",
    "    \"https://www.kaggle.com/datasets/utkarshx27/health-services-in-metropolitan-areas\",\n",
    "    \"https://www.kaggle.com/datasets/kanchana1990/colorado-healthcare-decoding-no-show-patterns\",\n",
    "    \"https://www.kaggle.com/datasets/gauravduttakiit/reproductive-childhealthcare-classification\",\n",
    "    \"https://www.kaggle.com/datasets/meeratif/global-healthcare-pricess\",\n",
    "    \"https://www.kaggle.com/datasets/uom190346a/disease-symptoms-and-patient-profile-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/nanditapore/medical-cost-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/daminitiwari/insurance\",\n",
    "    \"https://www.kaggle.com/datasets/rivalytics/healthcare-workforce-mental-health-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/ankushpanday1/colorectal-cancer-risk-and-survival-data\",\n",
    "    \"https://www.kaggle.com/datasets/iamsouravbanerjee/life-expectancy-at-birth-across-the-globe\",\n",
    "    \"https://www.kaggle.com/datasets/heidarmirhajisadati/regional-cost-of-living-analysis\",\n",
    "    \"https://www.kaggle.com/datasets/jobspikr/30000-latest-healthcare-jobs-emedcareers-europe\",\n",
    "    \"https://www.kaggle.com/datasets/anshulmahajan14/healthcare-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/mrsimple07/obesity-prediction\",\n",
    "    \"https://www.kaggle.com/datasets/harshsingh2209/supply-chain-analysis\",\n",
    "    \"https://www.kaggle.com/datasets/amirmotefaker/supply-chain-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/aranyogeshm/healthcare-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/adishgolechha/ecommerce-healthcare-orders-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/simranjitkhehra/healthcare-patient-record\",\n",
    "    \"https://www.kaggle.com/datasets/sunayanagawde/flipkart-healthcare-products-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/muhammadehsan02/healthcare-prediction-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/ashutoshswarnakar/healthcare-patient-records\",\n",
    "    \"https://www.kaggle.com/datasets/prasad22/pmc-hospital-infrastructure\",\n",
    "    \"https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/nelgiriyewithana/countries-of-the-world-2023\",\n",
    "    \"https://www.kaggle.com/datasets/hasibur013/diabetes-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/divyabhavana/synthetic-healthcare-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/shashwatwork/wellbeing-of-healthcare-professionals-in-india\",\n",
    "    \"https://www.kaggle.com/datasets/simran726/healthcare-patient-monitoring-data\",\n",
    "    \"https://www.kaggle.com/datasets/kapoorprakhar/cardio-health-risk-assessment-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/rabieelkharoua/predict-liver-disease-1700-records-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/zsinghrahulk/aids-clinical-trials-group-study-175\",\n",
    "    \"https://www.kaggle.com/datasets/willianoliveiragibin/annual-cause-death-numbers\",\n",
    "    \"https://www.kaggle.com/datasets/samira1992/diabetes-intermediate-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/sresthajain/medical-diagnosis-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/lingyoungloon/who-healthcare-systems\",\n",
    "    \"https://www.kaggle.com/datasets/mayankgupta96/healthcare\",\n",
    "    \"https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification\",\n",
    "    \"https://www.kaggle.com/datasets/zain280/diabeties-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/hasaanrana/diet-exercise-and-pcos-insights\",\n",
    "    \"https://www.kaggle.com/datasets/ankushpanday1/pancreatic-cancer-prediction-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/ashaychoudhary/anxiety-attack-factors-symptoms-and-severity\",\n",
    "    \"https://www.kaggle.com/datasets/godfatherfigure/healthcare-dataset-stroke-data\",\n",
    "    \"https://www.kaggle.com/datasets/awais8765/healthcare-diabetes\",\n",
    "    \"https://www.kaggle.com/datasets/mahad049/heart-health-stats-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/hhs/health-insurance\",\n",
    "    \"https://www.kaggle.com/datasets/prashikmeshram37/healthcare-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/samira1992/countries-intermediate-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/hasibur013/bangladesh-hospital-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/rajagrawal7089/healthcare\",\n",
    "    \"https://www.kaggle.com/datasets/joymarhew/medical-reccomadation-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/mattop/burger-king-menu-nutrition-data\",\n",
    "    \"https://www.kaggle.com/datasets/ankushpanday1/diabetes-prediction-in-india-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/jatinthakur706/copd-asthma-patient-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/gyanashish/healthcare-diabetes\",\n",
    "    \"https://www.kaggle.com/datasets/omegasaransh12/reproductive-childhealthcare\",\n",
    "    \"https://www.kaggle.com/datasets/splcher/adverse-hospital-events-in-california\",\n",
    "    \"https://www.kaggle.com/datasets/ulrikthygepedersen/life-expectancy\",\n",
    "    \"https://www.kaggle.com/datasets/danevans/world-bank-wdi-212-health-systems\",\n",
    "    \"https://www.kaggle.com/datasets/nvlkumar/healthcare-diabetes\",\n",
    "    \"https://www.kaggle.com/datasets/waqi786/brain-tumor-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/shriyashjagtap/heart-attack-risk-assessment-dataset\",\n",
    "    \"https://www.kaggle.com/datasets/mathurinache/invehicle-coupon-recommendation\",\n",
    "    \"https://www.kaggle.com/datasets/rasooljader/gestational-diabetes\",\n",
    "    \"https://www.kaggle.com/datasets/noeyislearning/framingham-heart-study\",\n",
    "    \"https://openml.org/search?type=data&status=any&tags.tag=healthcare&sort=match&id=40883\",\n",
    "    \"https://openml.org/search?type=data&status=any&tags.tag=healthcare&sort=match&id=42865\",\n",
    "    \"https://openml.org/search?type=data&status=any&tags.tag=healthcare&sort=match&id=1464\",\n",
    "    \"https://openml.org/search?type=data&status=any&tags.tag=healthcare&sort=match&id=40922\",\n",
    "    \"https://openml.org/search?type=data&status=any&tags.tag=healthcare&sort=match&id=1509\",\n",
    "    \"https://openml.org/search?type=data&status=any&tags.tag=healthcare&sort=match&id=1523\",\n",
    "    \"https://openml.org/search?type=data&status=any&tags.tag=healthcare&sort=match&id=4153\",\n",
    "    \"https://openml.org/search?type=data&status=any&tags.tag=healthcare&sort=match&id=960\",\n",
    "    \"https://openml.org/search?type=data&status=any&tags.tag=healthcare&sort=match&id=43150\",\n",
    "    \"https://openml.org/search?type=data&status=any&tags.tag=healthcare&id=1464\",\n",
    "    \"https://openml.org/search?type=data&status=any&sort=match&id=43781\",\n",
    "    \"https://openml.org/search?type=data&status=any&sort=match&id=43827\",\n",
    "    \"https://openml.org/search?type=data&status=any&sort=match&id=42738\",\n",
    "    \"https://openml.org/search?type=data&status=any&sort=match&id=43896\",\n",
    "    \"https://openml.org/search?type=data&status=any&sort=match&id=43897\",\n",
    "    \"https://openml.org/search?type=data&status=any&sort=match&id=43457\",\n",
    "    \"https://openml.org/search?type=data&status=any&sort=match&id=42878\",\n",
    "    \"https://openml.org/search?type=data&status=any&sort=match&id=46101\",\n",
    "    \"https://openml.org/search?type=data&status=any&sort=match&id=46076\",\n",
    "    \"https://openml.org/search?type=data&status=any&sort=match&id=43414\",\n",
    "    \"https://huggingface.co/datasets/naabiil/Obesity_Levels_Estimation\",\n",
    "    \"https://huggingface.co/datasets/aai510-group1/telco-customer-churn\",\n",
    "    \"https://huggingface.co/datasets/imodels/credit-card\",\n",
    "    \"https://huggingface.co/datasets/mstz/heart_failure\",\n",
    "    \"https://huggingface.co/datasets/Einstellung/demo-salaries\",\n",
    "    \"https://huggingface.co/datasets/katossky/wine-recognition\",\n",
    "    \"https://huggingface.co/datasets/Ozziey/poems_dataset\",\n",
    "    \"https://huggingface.co/datasets/wwydmanski/wisconsin-breast-cancer\",\n",
    "    \"https://huggingface.co/datasets/wwydmanski/tabular-letter-recognition\",\n",
    "    \"https://huggingface.co/datasets/mstz/heloc\",\n",
    "    \"https://huggingface.co/datasets/mstz/student_performance\",\n",
    "    \"https://huggingface.co/datasets/mstz/compas\",\n",
    "    \"https://huggingface.co/datasets/mstz/german\",\n",
    "    \"https://huggingface.co/datasets/mstz/annealing\",\n",
    "    \"https://huggingface.co/datasets/mstz/sonar\",\n",
    "]\n",
    "\n",
    "aggregated_results = {\n",
    "    \"outliers\": {\"train\": [], \"val\": [], \"test\": []},\n",
    "    \"label_issues\": {\"train\": [], \"val\": [], \"test\": []},\n",
    "    \"near_duplicates\": {\"tvc\": [], \"ttc\": [], \"vtc\": [], \"genc\": []},\n",
    "    \"leakage_correlation\": [],\n",
    "    \"data_balance\": [],\n",
    "}\n",
    "\n",
    "aggregated_metrics_original: Dict[str, Dict[str, List[float | str]]] = {\n",
    "    \"binary\": {\n",
    "        \"dataset_name\": [],\n",
    "        \"count\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"balanced_accuracy\": [],\n",
    "        \"f1\": [],\n",
    "        \"precision\": [],\n",
    "        \"sensitivity/recall\": [],\n",
    "        \"selection rate\": [],\n",
    "        \"specificity/selectivity\": [],\n",
    "        \"false positive rate\": [],\n",
    "        \"false negative rate\": [],\n",
    "        \"MCC\": [],\n",
    "        \"demographic parity difference\": [],\n",
    "        \"demographic parity ratio\": [],\n",
    "        \"equalized odds difference\": [],\n",
    "        \"equalized odds ratio\": [],\n",
    "        \"equal opportunity difference\": [],\n",
    "        \"equal opportunity ratio\": [],\n",
    "    },\n",
    "    \"multiclass\": {\n",
    "        \"dataset_name\": [],\n",
    "        \"count\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"balanced_accuracy\": [],\n",
    "        \"f1\": [],\n",
    "        \"precision\": [],\n",
    "        \"sensitivity/recall\": [],\n",
    "        \"MCC\": [],\n",
    "    },\n",
    "    \"regression\": {\n",
    "        \"dataset_name\": [],\n",
    "        \"count\": [],\n",
    "        \"MAE\": [],\n",
    "        \"MSE\": [],\n",
    "        \"RMSE\": [],\n",
    "        \"MdAE\": [],\n",
    "        \"MAPE\": [],\n",
    "        \"R2\": [],\n",
    "    },\n",
    "}\n",
    "\n",
    "aggregated_metrics_cleaned: Dict[str, Dict[str, List[float | str]]] = {\n",
    "    \"binary\": {\n",
    "        \"dataset_name\": [],\n",
    "        \"count\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"balanced_accuracy\": [],\n",
    "        \"f1\": [],\n",
    "        \"precision\": [],\n",
    "        \"sensitivity/recall\": [],\n",
    "        \"selection rate\": [],\n",
    "        \"specificity/selectivity\": [],\n",
    "        \"false positive rate\": [],\n",
    "        \"false negative rate\": [],\n",
    "        \"MCC\": [],\n",
    "        \"demographic parity difference\": [],\n",
    "        \"demographic parity ratio\": [],\n",
    "        \"equalized odds difference\": [],\n",
    "        \"equalized odds ratio\": [],\n",
    "        \"equal opportunity difference\": [],\n",
    "        \"equal opportunity ratio\": [],\n",
    "    },\n",
    "    \"multiclass\": {\n",
    "        \"dataset_name\": [],\n",
    "        \"count\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"balanced_accuracy\": [],\n",
    "        \"f1\": [],\n",
    "        \"precision\": [],\n",
    "        \"sensitivity/recall\": [],\n",
    "        \"MCC\": [],\n",
    "    },\n",
    "    \"regression\": {\n",
    "        \"dataset_name\": [],\n",
    "        \"count\": [],\n",
    "        \"MAE\": [],\n",
    "        \"MSE\": [],\n",
    "        \"RMSE\": [],\n",
    "        \"MdAE\": [],\n",
    "        \"MAPE\": [],\n",
    "        \"R2\": [],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def update_metrics_for_type(\n",
    "    problem_type: str,\n",
    "    original_rows: Iterator[Dict[str, Any]],\n",
    "    cleaned_rows: Iterator[Dict[str, Any]],\n",
    "    dataset_path: str,\n",
    "    metrics_original: Dict[str, Dict[str, List[float | str]]],\n",
    "    metrics_cleaned: Dict[str, Dict[str, List[float | str]]],\n",
    ") -> None:\n",
    "    for original, cleaned in zip(original_rows, cleaned_rows):\n",
    "        metrics_original[problem_type][original[\"metric\"]].append(original[\"value\"])\n",
    "        metrics_cleaned[problem_type][cleaned[\"metric\"]].append(cleaned[\"value\"])\n",
    "\n",
    "    metrics_original[problem_type][\"dataset_name\"].append(str(dataset_path))\n",
    "    metrics_cleaned[problem_type][\"dataset_name\"].append(str(dataset_path))\n",
    "\n",
    "\n",
    "def update_aggregate_metrics(\n",
    "    original_metric: Dict[str, Dict[str, pl.DataFrame]],\n",
    "    automl_data: AutoMLData,\n",
    "    cleaned_metric: Dict[str, Dict[str, pl.DataFrame]],\n",
    "):\n",
    "    if any(input is None for input in [original_metric, cleaned_metric, automl_data]):\n",
    "        for input in [original_metric, cleaned_metric, automl_data]:\n",
    "            if input is None:\n",
    "                print(f\"🚨 calculating metrics: Input {input} is None\")\n",
    "        return\n",
    "    original_overall = original_metric[list(original_metric.keys())[0]][\"overall\"]\n",
    "    cleaned_overall = cleaned_metric[list(cleaned_metric.keys())[0]][\"overall\"]\n",
    "    if not original_overall[\"metric\"].equals(cleaned_overall[\"metric\"]):\n",
    "        print(\"🚨 calculating metrics: Original and cleaned metrics are not the same\")\n",
    "        return\n",
    "    for df, name in [(original_overall, \"original\"), (cleaned_overall, \"cleaned\")]:\n",
    "        for row in df.iter_rows(named=True):\n",
    "            metric_name = row[\"metric\"]\n",
    "            metric_value = row[\"value\"]\n",
    "            if not isinstance(metric_value, (float, int)) or metric_value is None:\n",
    "                print(f\"🚨 calculating metrics: Metric {metric_name} contains invalid values in {name} metrics\")\n",
    "                return\n",
    "    if automl_data[\"problem_type\"] not in [\"binary\", \"multiclass\", \"regression\"]:\n",
    "        print(\"🚨 calculating metrics: Invalid problem_type\")\n",
    "        return\n",
    "    update_metrics_for_type(\n",
    "        automl_data[\"problem_type\"],\n",
    "        original_overall.iter_rows(named=True),\n",
    "        cleaned_overall.iter_rows(named=True),\n",
    "        str(automl_data[\"path\"]),\n",
    "        aggregated_metrics_original,\n",
    "        aggregated_metrics_cleaned,\n",
    "    )\n",
    "    print(f\"✅ Successfully updated metrics for {automl_data['path']}\")\n",
    "\n",
    "\n",
    "for d in tqdm(datasets):\n",
    "    try:\n",
    "        # Get Raw Data\n",
    "        data = get_dataset(d)\n",
    "        data_path = data[\"path\"]\n",
    "        if os.path.exists(f\"{data_path}/raw_data.pkl\"):\n",
    "            with open(f\"{data_path}/raw_data.pkl\", \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "        else:\n",
    "            with open(f\"{data_path}/raw_data.pkl\", \"wb\") as f:\n",
    "                pickle.dump(data, f)\n",
    "\n",
    "        print(f\"Target: {data['target']}\")\n",
    "        print(f\"Sensitive: {data['sensitive_features']}\")\n",
    "        # Preprocess Data\n",
    "        proccessed_data = autoML_prep(data)\n",
    "        # Run AutoML 1\n",
    "        if os.path.exists(f\"{data_path}/automl_original.pkl\"):\n",
    "            print(\"Loading original AutoML\")\n",
    "            with open(f\"{data_path}/automl_original.pkl\", \"rb\") as f:\n",
    "                original_automl = pickle.load(f)\n",
    "            original_automl_data = original_automl.auto_ml_data\n",
    "        else:\n",
    "            print(\"Running original AutoML\")\n",
    "            original_automl = AutoMLModel(proccessed_data, time_limit=300, preset=\"good\", load=False, verbosity=0)\n",
    "            original_automl.run_auto_ml()\n",
    "            original_automl_data = original_automl.auto_ml_data\n",
    "            if original_automl_data[\"problem_type\"] != \"regression\":\n",
    "                original_train_pred = original_automl.predict_proba(\"train\")\n",
    "                original_test_pred = original_automl.predict_proba(\"test\")\n",
    "                combined_prob_original = pl.concat([original_train_pred, original_test_pred], how=\"vertical\").to_numpy()\n",
    "            else:\n",
    "                combined_prob_original = None\n",
    "            with open(f\"{data_path}/automl_original.pkl\", \"wb\") as f:\n",
    "                pickle.dump(original_automl, f)\n",
    "\n",
    "        # Profile Data\n",
    "        if os.path.exists(f\"{data_path}/data_summary.pkl\"):\n",
    "            with open(f\"{data_path}/data_summary.pkl\", \"rb\") as f:\n",
    "                data_summary = pickle.load(f)\n",
    "            profiled_data = data_summary.export()\n",
    "        else:\n",
    "            if original_automl_data[\"problem_type\"] != \"regression\":\n",
    "                original_train_pred = original_automl.predict_proba(\"train\")\n",
    "                original_test_pred = original_automl.predict_proba(\"test\")\n",
    "                combined_prob_original = pl.concat([original_train_pred, original_test_pred], how=\"vertical\").to_numpy()\n",
    "            else:\n",
    "                combined_prob_original = None\n",
    "            if combined_prob_original is None:\n",
    "                data_summary = DataSummary(proccessed_data)\n",
    "            else:\n",
    "                data_summary = DataSummary(proccessed_data, pred_probs=combined_prob_original)\n",
    "            data_summary.create_summary()\n",
    "            profiled_data = data_summary.export()\n",
    "            with open(f\"{data_path}/data_summary.pkl\", \"wb\") as f:\n",
    "                pickle.dump(data_summary, f)\n",
    "\n",
    "        #  original metrics 1\n",
    "        if os.path.exists(f\"{data_path}/original_metrics.pkl\"):\n",
    "            with open(f\"{data_path}/original_metrics.pkl\", \"rb\") as f:\n",
    "                original_metrics = pickle.load(f)\n",
    "        else:\n",
    "            fas_original = FairnessAssessor(original_automl_data)\n",
    "            fas_original.analyze_all(intersections=False, feature_type=\"only one\")\n",
    "            original_metrics = fas_original.get_all_metrics()\n",
    "            with open(f\"{data_path}/original_metrics.pkl\", \"wb\") as f:\n",
    "                pickle.dump(original_metrics, f)\n",
    "        # Run AutoML 2\n",
    "        if os.path.exists(f\"{data_path}/automl_cleaned.pkl\"):\n",
    "            with open(f\"{data_path}/automl_cleaned.pkl\", \"rb\") as f:\n",
    "                cleaned_automl = pickle.load(f)\n",
    "            cleaned_automl_data = cleaned_automl.auto_ml_data\n",
    "        else:\n",
    "            print(\"Running cleaned AutoML\")\n",
    "            cleaned_dict = data_summary.solve_issues(return_results=True, consider_near_duplicates=False)\n",
    "            if cleaned_dict[\"train\"] is not None:\n",
    "                data[\"train\"] = cleaned_dict[\"train\"]\n",
    "            if cleaned_dict[\"val\"] is not None:\n",
    "                data[\"val\"] = cleaned_dict[\"val\"]\n",
    "            if cleaned_dict[\"test\"] is not None:\n",
    "                data[\"test\"] = cleaned_dict[\"test\"]\n",
    "            cleaned_proccessed_data = autoML_prep(data)\n",
    "            cleaned_automl = AutoMLModel(cleaned_proccessed_data, time_limit=300, preset=\"good\", load=False, verbosity=0)\n",
    "            cleaned_automl.run_auto_ml()\n",
    "            cleaned_automl_data = cleaned_automl.auto_ml_data\n",
    "            with open(f\"{data_path}/automl_cleaned.pkl\", \"wb\") as f:\n",
    "                pickle.dump(cleaned_automl, f)\n",
    "        # metrics 2\n",
    "        if os.path.exists(f\"{data_path}/cleaned_metrics.pkl\"):\n",
    "            with open(f\"{data_path}/cleaned_metrics.pkl\", \"rb\") as f:\n",
    "                cleaned_metrics = pickle.load(f)\n",
    "        else:\n",
    "            fas_cleaned = FairnessAssessor(cleaned_automl_data)\n",
    "            fas_cleaned.analyze_all(intersections=False, feature_type=\"only one\")\n",
    "            cleaned_metrics = fas_cleaned.get_all_metrics()\n",
    "            with open(f\"{data_path}/cleaned_metrics.pkl\", \"wb\") as f:\n",
    "                pickle.dump(cleaned_metrics, f)\n",
    "        update_aggregate_metrics(original_metrics, original_automl_data, cleaned_metrics)\n",
    "        issue_summary = data_summary.quick_summary()\n",
    "        print(issue_summary[\"string_output\"])\n",
    "\n",
    "        with open(f\"{data_path}/statistics.pkl\", \"wb\") as f:\n",
    "            pickle.dump(issue_summary, f)\n",
    "        # Aggregate Results\n",
    "        for key in [\"train\", \"val\", \"test\"]:\n",
    "            aggregated_results[\"outliers\"][key].append(issue_summary[\"outliers\"].get(key, 0))\n",
    "        for key in [\"train\", \"val\", \"test\"]:\n",
    "            aggregated_results[\"label_issues\"][key].append(issue_summary[\"label_issues\"].get(key, 0))\n",
    "        for key in [\"tvc\", \"ttc\", \"vtc\", \"genc\"]:\n",
    "            aggregated_results[\"near_duplicates\"][key].append(issue_summary[\"near_duplicates\"].get(key, 0))\n",
    "        aggregated_results[\"leakage_correlation\"].append(issue_summary.get(\"leakage_correlation\", 0))\n",
    "        aggregated_results[\"data_balance\"].append(issue_summary.get(\"data_balance\", 0))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 Skipping Dataset: {e}\")\n",
    "        with open(f\"{data_path}/errors.txt\", \"a\") as error_file:\n",
    "            error_file.write(str(e))\n",
    "        continue\n",
    "\n",
    "with open(\"aggregated_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(aggregated_results, f)\n",
    "with open(\"aggregated_metrics_original.pkl\", \"wb\") as f:\n",
    "    pickle.dump(aggregated_metrics_original, f)\n",
    "with open(\"aggregated_metrics_cleaned.pkl\", \"wb\") as f:\n",
    "    pickle.dump(aggregated_metrics_cleaned, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
